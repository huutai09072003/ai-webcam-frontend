import React, {
  useRef,
  useState,
} from 'react';

const CameraStreamCapture: React.FC = () => {
  const videoRef = useRef<HTMLVideoElement | null>(null);
  const canvasRef = useRef<HTMLCanvasElement | null>(null);
  const [capturedImage, setCapturedImage] = useState<string | null>(null);
  const [predictions, setPredictions] = useState<any[]>([]);
  const [isProcessing, setIsProcessing] = useState(false); // Tr·∫°ng th√°i x·ª≠ l√Ω
  const [errorMessage, setErrorMessage] = useState<string | null>(null); // Th√¥ng b√°o l·ªói khi kh√¥ng ph√°t hi·ªán nh√£n

  const startCamera = () => {
    if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
      navigator.mediaDevices
        .getUserMedia({ video: true })
        .then((stream) => {
          if (videoRef.current) {
            videoRef.current.srcObject = stream;
          }
        })
        .catch((err) => console.error('L·ªói khi kh·ªüi t·∫°o camera:', err));
    }
  };

  const stopCamera = () => {
    if (videoRef.current?.srcObject) {
      const stream = videoRef.current.srcObject as MediaStream;
      const tracks = stream.getTracks();
      tracks.forEach((track) => track.stop());
      videoRef.current.srcObject = null;
    }
  };

  const captureImage = () => {
    if (canvasRef.current && videoRef.current) {
      const ctx = canvasRef.current.getContext('2d');
      canvasRef.current.width = videoRef.current.videoWidth;
      canvasRef.current.height = videoRef.current.videoHeight;
      ctx?.drawImage(videoRef.current, 0, 0, canvasRef.current.width, canvasRef.current.height);

      const base64Image = canvasRef.current.toDataURL();
      setCapturedImage(base64Image);
      setIsProcessing(true); // B·∫Øt ƒë·∫ßu qu√° tr√¨nh x·ª≠ l√Ω
      setErrorMessage(null); // Reset th√¥ng b√°o l·ªói

      sendToBackend(base64Image);
    }
  };

  const sendToBackend = (imageBase64: string) => {
    fetch('http://localhost:8000/analyze-captured-image', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({ image_base64: imageBase64 }),
    })
      .then((response) => response.json())
      .then((data) => {
        console.log('K·∫øt qu·∫£ nh·∫≠n di·ªán:', data);
        setIsProcessing(false); // X·ª≠ l√Ω xong

        // Ki·ªÉm tra n·∫øu kh√¥ng ph√°t hi·ªán nh√£n n√†o
        if (data.predictions.length === 0) {
          setErrorMessage('Kh√¥ng ph√°t hi·ªán ƒë∆∞·ª£c b·∫•t k·ª≥ lo·∫°i r√°c n√†o.');
        } else {
          setPredictions(data.predictions);
          setCapturedImage(data.image_with_boxes);
        }
      })
      .catch((error) => {
        setIsProcessing(false); // X·ª≠ l√Ω xong
        console.error('L·ªói khi g·ª≠i ·∫£nh:', error);
        setErrorMessage('C√≥ l·ªói x·∫£y ra khi x·ª≠ l√Ω ·∫£nh.');
      });
  };

  return (
    <div className="p-6">
      <h1 className="text-2xl font-bold text-green-700 mb-4">üì∏ Ch·ª•p ·∫£nh v√† nh·∫≠n di·ªán</h1>

      <div className="flex justify-between mb-4">
        {/* Camera Section */}
        <div className="w-[48%]">
          <div className="mb-4 flex justify-center gap-2">
            <button onClick={startCamera} className="px-4 py-2 rounded bg-green-500 hover:bg-green-600 text-white">
              B·∫Øt ƒë·∫ßu
            </button>
            <button onClick={stopCamera} className="px-4 py-2 rounded bg-red-500 hover:bg-red-600 text-white">
              K·∫øt th√∫c
            </button>
          </div>
          <div className="relative flex justify-center">
            <video ref={videoRef} width="100%" height="auto" autoPlay muted className="border border-green-300 rounded shadow" />
          </div>
          <div className="relative flex justify-center mt-4">
            <canvas ref={canvasRef} style={{ display: 'none' }}></canvas>
            <button
              onClick={captureImage}
              className={`px-4 py-2 mt-2 rounded ${isProcessing ? 'bg-gray-400 cursor-not-allowed' : 'bg-blue-500 hover:bg-blue-600'} text-white`}
              disabled={isProcessing}
            >
              {isProcessing ? 'ƒêang x·ª≠ l√Ω...' : 'üì∏ Ch·ª•p ·∫£nh'}
            </button>
          </div>
        </div>

        {/* Image Results Section */}
        <div className="w-[48%] border-2 border-dashed border-gray-300 p-4 rounded-md">
          <h2 className="text-lg font-semibold text-green-700 mb-2">K·∫øt qu·∫£ nh·∫≠n di·ªán (·∫¢nh ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω)</h2>

          {/* Hi·ªÉn th·ªã ch√∫ th√≠ch */}
          <p className="text-sm text-gray-600 mb-4">
            ƒê√¢y l√† khu v·ª±c hi·ªÉn th·ªã k·∫øt qu·∫£ nh·∫≠n di·ªán c·ªßa b·∫°n. ·∫¢nh ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω v√† c√°c bounding boxes s·∫Ω ƒë∆∞·ª£c hi·ªÉn th·ªã c√πng v·ªõi c√°c nh√£n.
          </p>

          {capturedImage && !errorMessage && (
            <div className="flex justify-center mb-4">
              <img src={capturedImage} alt="Captured" width="100%" height="auto" className="rounded shadow" />
            </div>
          )}

          {/* Hi·ªÉn th·ªã th√¥ng b√°o l·ªói n·∫øu kh√¥ng ph√°t hi·ªán nh√£n */}
          {errorMessage && (
            <div className="text-red-600 font-semibold">
              <p>{errorMessage}</p>
            </div>
          )}

          {/* Hi·ªÉn th·ªã c√°c nh√£n v√† bounding boxes n·∫øu c√≥ k·∫øt qu·∫£ */}
          {predictions.length > 0 && !errorMessage && (
            <div className="mt-2">
              <h3 className="text-lg font-semibold text-green-700">C√°c nh√£n v√† s·ªë l∆∞·ª£ng:</h3>
              <ul className="text-left">
                {predictions.map((prediction, idx) => (
                  <li key={idx} className="text-sm text-gray-700">
                    {prediction.label}: {Math.round(prediction.confidence * 100)}% (V·ªã tr√≠: {prediction.box.join(', ')})
                  </li>
                ))}
              </ul>
            </div>
          )}
        </div>
      </div>
    </div>
  );
};

export default CameraStreamCapture;
